<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZKXM8P5V7J"></script> <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-ZKXM8P5V7J');
</script> <meta name="google-site-verification" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Khai Nguyen </title> <meta name="author" content="Khai Nguyen"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="/assets/libs/mdb/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="/assets/libs/google_fonts/google-fonts.css"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/Khai_photo.jpg?faa17597f415ad45662f7f975a9f8fdd"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://khainb.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6B%68%61%69%6E%62@%75%74%65%78%61%73.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/khainb" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/khai-nguyen-307895155" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://www.researchgate.net/profile/Khai-Nguyen-37/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://scholar.google.com/citations?user=im5fNaQAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/khainb_ml" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Khai</span> Nguyen </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/khai2-480.webp 480w,/assets/img/khai2-800.webp 800w,/assets/img/khai2-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/khai2.png?af050666375dfb779f4266b6022dfc7b" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="khai2.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>Hi! I’m Khai, a final-year Ph.D. candidate at <a href="https://stat.utexas.edu/" rel="external nofollow noopener" target="_blank">Department of Statistics and Data Sciences</a>, <a href="https://www.utexas.edu/" rel="external nofollow noopener" target="_blank">University of Texas at Austin</a>. I am fortunate to be advised by Professor <a href="https://nhatptnk8912.github.io/" rel="external nofollow noopener" target="_blank">Nhat Ho</a> and Professor <a href="https://www.ma.utexas.edu/component/cobalt/item/15-mathematics/364-mueller-peter?Itemid=1259" rel="external nofollow noopener" target="_blank">Peter Müller</a>, and to be associated with Institute for Foundations of Machine Learning (<a href="https://www.ifml.institute/" rel="external nofollow noopener" target="_blank">IFML</a>). I graduated from <a href="https://soict.hust.edu.vn/" rel="external nofollow noopener" target="_blank">Hanoi University of Science and Technology</a> with a Computer Science Bachelor’s degree. Before joining UT Austin, I was an AI Research Resident at <a href="http://www.vinai.io" rel="external nofollow noopener" target="_blank">VinAI Research</a> (acquired by Qualcomm AI Research) under the supervision of <a href="https://sites.google.com/site/buihhung/" rel="external nofollow noopener" target="_blank">Dr. Hung Bui</a>.</p> <p><span style="color:red; font-weight:bold"> I’m on the job market! Please feel free to contact me if interested in my research! </span> <img src="https://khainb.github.io/assets/intro.gif" alt="GIF description" style="width: 100%; height: auto;"></p> <p><em>(This video is created by using my proposed <a href="https://arxiv.org/pdf/2304.13586.pdf" rel="external nofollow noopener" target="_blank">energy-based sliced Wasserstein distance</a>.)</em></p> <p><strong>Research:</strong> My research focuses on both fundamental problems and applied problems in statistics, statistical machine learning, and deep learning.</p> <p><strong><em>1. Computational Optimal Transport.</em></strong> My research makes <a href="https://en.wikipedia.org/wiki/Transportation_theory_(mathematics)" rel="external nofollow noopener" target="_blank">Optimal Transport</a> scalable for statistical inference (with low time complexity, space complexity, and sample complexity) through a random projection approach known as sliced optimal transport (SOT). My work focuses on four key sub-domains of SOT: Monte Carlo methods, generalized Radon transform, weighted Radon transform, and nonparametric estimation. In addition, I contribute to variational problems in SOT, such as the sliced Wasserstein barycenter and sliced Wasserstein kernels. Finally, I broaden the applications of SOT across machine learning, statistics, and computer graphics and vision. I wrote a monograph on <a href="https://arxiv.org/pdf/2508.12519" rel="external nofollow noopener" target="_blank">SOT</a>, providing a synthesized introduction to the topic.</p> <p><strong><em>2. Statistical Inference and Decision Making.</em></strong> I formulate new inference and decision problems, such as Bayesian multivariate density-density regression and random partition summarization with a decision-theoretic approach. I also leverage OT and SOT to improve the scalability and accuracy of statistical estimation in machine learning applications, including generative modeling, representation learning, and domain adaptation.</p> <p><strong><em>3. Geometric Data Processing.</em></strong> Geometric data, such as 3D point clouds and meshes, can be naturally represented as distributions over geometric spaces. I develop scalable statistical models for deforming, reconstructing, and matching 3D shapes, enabling applications in medical imaging (e.g., cortical surface reconstruction) as well as computer graphics and vision.</p> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 15vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Nov 03, 2025</th> <td> My monograph <strong>An Introduction to Sliced Optimal Transport</strong> is published at <a href="https://www.nowpublishers.com/article/Details/CGV-119" rel="external nofollow noopener" target="_blank"><strong>Foundations and Trends® in Computer Graphics and Vision</strong></a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 18, 2025</th> <td> 1 paper <strong>Unbiased Sliced Wasserstein Kernels for High-Quality Audio Captioning</strong> is accepted at <strong>NeurIPS 2025</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">May 01, 2025</th> <td> 1 paper <strong>Lightspeed Geometric Dataset Distance via Sliced Optimal Transport</strong> is accepted at <strong>ICML 2025</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 07, 2025</th> <td> My proposal <strong>Summarizing Bayesian Nonparametric Mixture Posterior - Sliced Optimal Transport Metrics for Gaussian Mixtures</strong> is accepted at <strong>The Bayesian Young Statisticians Meeting 2025</strong> as a talk in a session with discussion. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 27, 2025</th> <td> I’m thrilled to be awarded a travel grant for <strong>International Conference on Bayesian Nonparametrics (BNP 14)</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 26, 2025</th> <td> I’m thrilled to be awarded a <a href="https://gradschool.utexas.edu/funding/fellowships/grad-school/continuing" rel="external nofollow noopener" target="_blank"><strong>UT Austin Outstanding Graduate Research Fellowship</strong></a> which is a merit-based fellowship awarded based on academic achievements, research accomplishments, and potential for future contributions. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 11, 2025</th> <td> Our paper <strong>Towards Marginal Fairness Sliced Wasserstein Barycenter</strong> is selected as a <strong>spotlight</strong> at <strong>ICLR 2025</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 26, 2025</th> <td> My proposal <strong>Summarizing Bayesian Nonparametric Mixture Posterior - Sliced Optimal Transport Metrics for Gaussian Mixtures</strong> is accepted at <strong>14th International Conference on Bayesian Nonparametrics</strong> as a contributed talk. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 22, 2025</th> <td> 1 paper <strong>Towards Marginal Fairness Sliced Wasserstein Barycenter</strong> is accepted at <strong>ICLR 2025</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 26, 2024</th> <td> 1 paper <strong>Hierarchical Hybrid Sliced Wasserstein: A Scalable Metric for Heterogeneous Joint Distributions</strong> is accepted at <strong>NeurIPS 2024</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">May 01, 2024</th> <td> 1 paper <strong>Sliced Wasserstein with Random-Path Projecting Directions</strong> is accepted at <strong>ICML 2024</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 27, 2024</th> <td> 1 paper <strong>Integrating Efficient Optimal Transport and Functional Maps For Unsupervised Shape Correspondence Learning</strong> is accepted at <strong>CVPR 2024</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 19, 2024</th> <td> 2 papers <strong>Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts</strong>, <strong>On Parameter Estimation in Deviated Gaussian Mixture of Experts</strong> are accepted at <strong>AISTATS 2024</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 16, 2024</th> <td> 4 papers <strong>Quasi-Monte Carlo for 3D Sliced Wasserstein - Spotlight Presentation</strong>, <strong>Sliced Wasserstein Estimation with Control Variates</strong>, <strong>Diffeomorphic Deformation via Sliced Wasserstein Distance Optimization for Cortical Surface Reconstruction</strong>, and <strong>Revisiting Deep Audio-Text Retrieval Through the Lens of Transportation</strong> are accepted at <strong>ICLR 2024</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 21, 2023</th> <td> 4 papers <strong>Energy-Based Sliced Wasserstein Distance</strong>, <strong>Markovian sliced Wasserstein distances: Beyond independent projections</strong>, <strong>Designing robust Transformers using robust kernel density estimation</strong>, and <strong>Minimax optimal rate for parameter estimation in multivariate deviated models</strong> are accepted at <strong>NeurIPS 2023</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 24, 2023</th> <td> 1 paper <strong>Self-Attention Amortized Distributional Projection Optimization for Sliced Wasserstein Point-Cloud Reconstruction</strong> is accepted at <strong>ICML 2023</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 20, 2023</th> <td> 1 paper <strong>Hierarchical Sliced Wasserstein Distance</strong> is accepted at <strong>ICLR 2023</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 14, 2022</th> <td> 4 papers <strong>Revisiting Sliced Wasserstein on Images: From Vectorization to Convolution</strong>, <strong>Amortized Projection Optimization for Sliced Wasserstein Generative Models</strong>, <strong>Improving Transformer with an Admixture of Attention Heads</strong> , and <strong>FourierFormer: Transformer Meets Generalized Fourier Integral Theorem</strong> are accepted at <strong>NeurIPS 2022</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 24, 2022</th> <td> 2 papers <strong>Improving Mini-batch Optimal Transport via Partial Transportation</strong> and <strong>On Transportation of Mini-batches: A Hierarchical Approach</strong> are accepted at <strong>ICML 2022</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 24, 2021</th> <td> 2 papers <strong>Distributional Sliced-Wasserstein and Applications to Generative Modeling - Spotlight Presentation</strong> and <strong>Improving Relational Regularized Autoencoders with Spherical Sliced Fused Gromov Wasserstein</strong> are accepted at <strong>ICLR 2021</strong>. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Monograph</a> </h2> <div class="publications"> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#90D5FF"> <a href="https://www.nowpublishers.com/cgv" rel="external nofollow noopener" target="_blank">FnTCGV</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fntSOT-480.webp 480w,/assets/img/publication_preview/fntSOT-800.webp 800w,/assets/img/publication_preview/fntSOT-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/fntSOT.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="fntSOT.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2025introduction" class="col-sm-8"> <div class="title">An Introduction to Sliced Optimal Transport</div> <div class="author"> <em>Khai Nguyen</em> </div> <div class="periodical"> <em>Foundations and Trends® in Computer Graphics and Vision</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.nowpublishers.com/article/Details/CGV-119" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Sliced Optimal Transport (SOT) is a rapidly developing branch of optimal transport (OT) that exploits the tractability of one-dimensional OT problems. By combining tools from OT, integral geometry, and computational statistics, SOT enables fast and scalable computation of distances, barycenters, and kernels for probability measures, while retaining rich geometric structure. This monograph provides a comprehensive review of SOT, covering its mathematical foundations, methodological advances, computational methods, and applications. We discuss key concepts of OT and one-dimensional OT, the role of tools from integral geometry such as Radon transform in projecting measures, and statistical techniques for estimating sliced distances. The monograph further explores recent methodological advances, including non-linear projections, improved Monte Carlo approximations, statistical estimation techniques for one-dimensional optimal transport, weighted slicing techniques, and transportation plan estimation methods. Variational problems, such as minimum sliced Wasserstein estimation, barycenters, gradient flows, kernel constructions, and embeddings are examined alongside extensions to unbalanced, partial, multi-marginal, and Gromov-Wasserstein settings. Applications span machine learning, statistics, computer graphics and computer visions, highlighting SOT’s versatility as a practical computational tool. This work will be of interest to researchers and practitioners in machine learning, data sciences, and computational disciplines seeking efficient alternatives to classical OT.</p> </div> </div> </div> </li></ol> </div> <h2> <a href="/publications/" style="color: inherit">Selected Preprints</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/StreamSW-480.webp 480w,/assets/img/publication_preview/StreamSW-800.webp 800w,/assets/img/publication_preview/StreamSW-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/StreamSW.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="StreamSW.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2025s" class="col-sm-8"> <div class="title">Streaming Sliced Optimal Transport</div> <div class="author"> <em>Khai Nguyen</em> </div> <div class="periodical"> <em>Under Review</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2505.06835" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/khainb/StreamSW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Sliced optimal transport (SOT) or sliced Wasserstein (SW) distance is widely recognized for its statistical and computational scalability. In this work, we further enhance the computational scalability by proposing the first method for computing SW from sample streams, called \emphstreaming sliced Wasserstein (Stream-SW). To define Stream-SW, we first introduce the streaming computation of the one-dimensional Wasserstein distance. Since the one-dimensional Wasserstein (1DW) distance has a closed-form expression, given by the absolute difference between the quantile functions of the compared distributions, we leverage quantile approximation techniques for sample streams to define the streaming 1DW distance. By applying streaming 1DW to all projections, we obtain Stream-SW. The key advantage of Stream-SW is its low memory complexity while providing theoretical guarantees on the approximation error. We demonstrate that Stream-SW achieves a more accurate approximation of SW than random subsampling, with lower memory consumption, in comparing Gaussian distributions and mixtures of Gaussians from streaming samples. Additionally, we conduct experiments on point cloud classification, point cloud gradient flows, and streaming change point detection to further highlight the favorable performance of Stream-SW</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Preprint</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DDR-480.webp 480w,/assets/img/publication_preview/DDR-800.webp 800w,/assets/img/publication_preview/DDR-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/DDR.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DDR.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2025bayesian" class="col-sm-8"> <div class="title">Bayesian Multivariate Density-Density Regression</div> <div class="author"> <em>Khai Nguyen</em>, <a href="https://nystat.github.io/yni/" rel="external nofollow noopener" target="_blank">Yang Ni</a>, and <a href="https://www.ma.utexas.edu/component/cobalt/item/15-mathematics/364-mueller-peter?Itemid=1259" rel="external nofollow noopener" target="_blank">Peter Mueller</a> </div> <div class="periodical"> <em>Under Review</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2504.12617" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>We introduce a scalable framework for regressing multivariate distributions onto multivariate distributions, motivated by the application of inferring cell-cell communication from population-scale single-cell data. The observed data consist of pairs of multivariate distributions for ligands from one cell type and corresponding receptors from another. For each ordered pair e=(l,r) of cell types (l≠r) and each sample i=1,…,n, we observe a pair of distributions (Fei,Gei) of gene expressions for ligands and receptors of cell types l and r, respectively. The aim is to set up a regression of receptor distributions Gei given ligand distributions Fei. A key challenge is that these distributions reside in distinct spaces of differing dimensions. We formulate the regression of multivariate densities on multivariate densities using a generalized Bayes framework with the sliced Wasserstein distance between fitted and observed distributions. Finally, we use inference under such regressions to define a directed graph for cell-cell communications.</p> </div> </div> </div> </li> </ol> </div> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0383a3"> <a href="https://www.nowpublishers.com/cgv" rel="external nofollow noopener" target="_blank">JCGS</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Posteriorsummarization-480.webp 480w,/assets/img/publication_preview/Posteriorsummarization-800.webp 800w,/assets/img/publication_preview/Posteriorsummarization-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/Posteriorsummarization.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Posteriorsummarization.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2025mixture" class="col-sm-8"> <div class="title">Summarizing Bayesian Nonparametric Mixture Posterior and Sliced Optimal Transport Metrics for Gaussian Mixtures</div> <div class="author"> <em>Khai Nguyen</em>, and <a href="https://www.ma.utexas.edu/component/cobalt/item/15-mathematics/364-mueller-peter?Itemid=1259" rel="external nofollow noopener" target="_blank">Peter Mueller</a> </div> <div class="periodical"> <em>Accepted under minor revision at Journal of Computational and Graphical Statistics</em>, 2025 </div> <div class="periodical"> </div> <span class="honor"> Contributed Talk at BNP14, Talk in session with discussion at BAYSM25 </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2411.14674.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/khainb/sbnpm-sot" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Existing methods to summarize posterior inference for mixture models focus on identifying a point estimate of the implied random partition for clustering, with density estimation as a secondary goal (Wade and Ghahramani, 2018; Dahl et al., 2022). We propose a novel approach for summarizing posterior inference in nonparametric Bayesian mixture models, prioritizing density estimation of the mixing measure (or mixture) as an inference target. One of the key features is the model-agnostic nature of the approach, which remains valid under arbitrarily complex dependence structures in the underlying sampling model. Using a decision-theoretic framework, our method identifies a point estimate by minimizing posterior expected loss. A loss function is defined as a discrepancy between mixing measures. Estimating the mixing measure implies inference on the mixture density. Exploiting the discrete nature of the mixing measure, we use a version of sliced Wasserstein distance. We introduce two specific variants for Gaussian mixtures. The first, mixed sliced Wasserstein, applies generalized geodesic projections on the product of the Euclidean space and the manifold of symmetric positive definite matrices. The second, sliced mixture Wasserstein, leverages the linearity of Gaussian mixture measures for efficient projection.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#820000"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> <span class="award badge rounded w-100"> Spotlight </span> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fair-480.webp 480w,/assets/img/publication_preview/fair-800.webp 800w,/assets/img/publication_preview/fair-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/fair.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="fair.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2025fair" class="col-sm-8"> <div class="title">Towards Marginal Fairness Sliced Wasserstein Barycenter</div> <div class="author"> <em>Khai Nguyen<sup>*</sup></em> , Hai Nguyen<sup>*</sup>, and <a href="https://nhatptnk8912.github.io/" rel="external nofollow noopener" target="_blank">Nhat Ho</a> </div> <div class="periodical"> <em>International Conference on Learning Representations</em>, 2025 </div> <div class="periodical"> </div> <span class="honor"> Spotlight Presentation [3.2%] </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2405.07482.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/khainb/MFSWB" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="award hidden d-print-inline"> <p></p> <p>Spotlight</p> </div> <div class="abstract hidden"> <p>The sliced Wasserstein barycenter (SWB) is a widely acknowledged method for efficiently generalizing the averaging operation within probability measure spaces. However, achieving marginal fairness SWB, ensuring approximately equal distances from the barycenter to marginals, remains unexplored. The uniform weighted SWB is not necessarily the optimal choice to obtain the desired marginal fairness barycenter due to the heterogeneous structure of marginals and the non-optimality of the optimization. As the first attempt to tackle the problem, we define the marginal fairness sliced Wasserstein barycenter (MFSWB) as a constrained SWB problem. Due to the computational disadvantages of the formal definition, we propose two hyperparameter-free and computationally tractable surrogate MFSWB problems that implicitly minimize the distances to marginals and encourage marginal fairness at the same time. To further improve the efficiency, we perform slicing distribution selection and obtain the third surrogate definition by introducing a new slicing distribution that focuses more on marginally unfair projecting directions. We discuss the relationship of the three proposed problems and their relationship to sliced multi-marginal Wasserstein distance. Finally, we conduct experiments on finding 3D point-clouds averaging, color harmonization, and training of sliced Wasserstein autoencoder with class-fairness representation to show the favorable performance of the proposed surrogate MFSWB problems.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0048BA"> <a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/H2SW-480.webp 480w,/assets/img/publication_preview/H2SW-800.webp 800w,/assets/img/publication_preview/H2SW-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/H2SW.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="H2SW.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2024hybrid" class="col-sm-8"> <div class="title">Hierarchical Hybrid Sliced Wasserstein: A Scalable Metric for Heterogeneous Joint Distributions</div> <div class="author"> <em>Khai Nguyen</em>, and <a href="https://nhatptnk8912.github.io/" rel="external nofollow noopener" target="_blank">Nhat Ho</a> </div> <div class="periodical"> <em>Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2404.15378.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/khainb/H2SW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Sliced Wasserstein (SW) and Generalized Sliced Wasserstein (GSW) have been widely used in applications due to their computational and statistical scalability. However, the SW and the GSW are only defined between distributions supported on a homogeneous domain. This limitation prevents their usage in applications with heterogeneous joint distributions with marginal distributions supported on multiple different domains. Using SW and GSW directly on the joint domains cannot make a meaningful comparison since their homogeneous slicing operator i.e., Radon Transform (RT) and Generalized Radon Transform (GRT) are not expressive enough to capture the structure of the joint supports set. To address the issue, we propose two new slicing operators i.e., Partial Generalized Radon Transform (PGRT) and Hierarchical Hybrid Radon Transform (HHRT). In greater detail, PGRT is the generalization of Partial Radon Transform (PRT), which transforms a subset of function arguments non-linearly while HHRT is the composition of PRT and multiple domain-specific PGRT on marginal domain arguments. By using HHRT, we extend the SW into Hierarchical Hybrid Sliced Wasserstein (H2SW) distance which is designed specifically for comparing heterogeneous joint distributions. We then discuss the topological, statistical, and computational properties of H2SW. Finally, we demonstrate the favorable performance of H2SW in 3D mesh deformation, deep 3D mesh autoencoders, and datasets comparison.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#820000"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> <span class="award badge rounded w-100"> Spotlight </span> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/QSW-480.webp 480w,/assets/img/publication_preview/QSW-800.webp 800w,/assets/img/publication_preview/QSW-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/QSW.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="QSW.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2023quasi" class="col-sm-8"> <div class="title">Quasi-Monte Carlo for 3D Sliced Wasserstein</div> <div class="author"> <em>Khai Nguyen</em>, <a href="https://nbariletto.github.io/" rel="external nofollow noopener" target="_blank">Nicolas Bariletto</a>, and <a href="https://nhatptnk8912.github.io/" rel="external nofollow noopener" target="_blank">Nhat Ho</a> </div> <div class="periodical"> <em>International Conference on Learning Representations</em>, 2024 </div> <div class="periodical"> </div> <span class="honor"> Spotlight Presentation [5%] </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2309.11713.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/khainb/Quasi-SW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="award hidden d-print-inline"> <p></p> <p>Spotlight</p> </div> <div class="abstract hidden"> <p>Monte Carlo (MC) approximation has been used as the standard computation approach for the Sliced Wasserstein (SW) distance, which has an intractable expectation in its analytical form. However, the MC method is not optimal in terms of minimizing the absolute approximation error. To provide a better class of empirical SW, we propose quasi-sliced Wasserstein (QSW) approximations that rely on Quasi-Monte Carlo (QMC) methods. For a comprehensive investigation of QMC for SW, we focus on the 3D setting, specifically computing the SW between probability measures in three dimensions. In greater detail, we empirically verify various ways of constructing QMC points sets on the 3D unit-hypersphere, including Gaussian-based mapping, equal area mapping, generalized spiral points, and optimizing discrepancy energies. Furthermore, to obtain an unbiased estimation for stochastic optimization, we extend QSW into Randomized Quasi-Sliced Wasserstein (RQSW) by introducing randomness to the discussed low-discrepancy sequences. For theoretical properties, we prove the asymptotic convergence of QSW and the unbiasedness of RQSW. Finally, we conduct experiments on various 3D tasks, such as point-cloud comparison, point-cloud interpolation, image style transfer, and training deep point-cloud autoencoders, to demonstrate the favorable performance of the proposed QSW and RQSW variants.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#820000"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/CVSW-480.webp 480w,/assets/img/publication_preview/CVSW-800.webp 800w,/assets/img/publication_preview/CVSW-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/CVSW.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CVSW.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2023control" class="col-sm-8"> <div class="title">Sliced Wasserstein Estimation with Control Variates</div> <div class="author"> <em>Khai Nguyen</em>, and <a href="https://nhatptnk8912.github.io/" rel="external nofollow noopener" target="_blank">Nhat Ho</a> </div> <div class="periodical"> <em>International Conference on Learning Representations</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2305.00402.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/khainb/CV-SW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>The sliced Wasserstein (SW) distances between two probability measures are defined as the expectation of the Wasserstein distance between two one-dimensional projections of the two measures. The randomness comes from a projecting direction that is used to project the two input measures to one dimension. Due to the intractability of the expectation, Monte Carlo integration is performed to estimate the value of the SW distance. Despite having various variants, there has been no prior work that improves the Monte Carlo estimation scheme for the SW distance in terms of controlling its variance. To bridge the literature on variance reduction and the literature on the SW distance, we propose computationally efficient control variates to reduce the variance of the empirical estimation of the SW distance. The key idea is to first find Gaussian approximations of projected one-dimensional measures, then we utilize the closed-form of the Wasserstein-2 distance between two Gaussian distributions to design the control variates. In particular, we propose using a lower bound and an upper bound of the Wasserstein-2 distance between two fitted Gaussians as two computationally efficient control variates. We empirically show that the proposed control variate estimators can help to reduce the variance considerably when comparing measures over images and point-clouds. Finally, we demonstrate the favorable performance of the proposed control variate estimators in gradient flows to interpolate between two point-clouds and in deep generative modeling on standard image datasets, such as CIFAR10 and CelebA.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0048BA"> <a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/EBSW-480.webp 480w,/assets/img/publication_preview/EBSW-800.webp 800w,/assets/img/publication_preview/EBSW-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/EBSW.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="EBSW.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2023energy" class="col-sm-8"> <div class="title">Energy-Based Sliced Wasserstein Distance</div> <div class="author"> <em>Khai Nguyen</em>, and <a href="https://nhatptnk8912.github.io/" rel="external nofollow noopener" target="_blank">Nhat Ho</a> </div> <div class="periodical"> <em>Neural Information Processing Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2304.13586.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/khainb/EBSW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>The sliced Wasserstein (SW) distance has been widely recognized as a statistically effective and computationally efficient metric between two probability measures. A key component of the SW distance is the slicing distribution. There are two existing approaches for choosing this distribution. The first approach is using a fixed prior distribution. The second approach is optimizing for the best distribution which belongs to a parametric family of distributions and can maximize the expected distance. However, both approaches have their limitations. A fixed prior distribution is non-informative in terms of highlighting projecting directions that can discriminate two general probability measures. Doing optimization for the best distribution is often expensive and unstable. Moreover, designing the parametric family of the candidate distribution could be easily misspecified. To address the issues, we propose to design the slicing distribution as an energy-based distribution that is parameter-free and has the density proportional to an energy function of the projected one-dimensional Wasserstein distance. We then derive a novel sliced Wasserstein metric, energy-based sliced Waserstein (EBSW) distance, and investigate its topological, statistical, and computational properties via importance sampling, sampling importance resampling, and Markov Chain methods. Finally, we conduct experiments on point-cloud gradient flow, color transfer, and point-cloud reconstruction to show the favorable performance of the EBSW.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#4E6C50"> <a href="https://icml.cc/" rel="external nofollow noopener" target="_blank">ICML</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mPOT-480.webp 480w,/assets/img/publication_preview/mPOT-800.webp 800w,/assets/img/publication_preview/mPOT-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/mPOT.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mPOT.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="pmlr-v162-nguyen22e" class="col-sm-8"> <div class="title">Improving Mini-batch Optimal Transport via Partial Transportation</div> <div class="author"> <em>Khai Nguyen<sup>*</sup></em>, <a href="https://hsgser.github.io/" rel="external nofollow noopener" target="_blank">Dang Nguyen<sup>*</sup></a>, The-Anh Vu Le, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Tung Pham, Nhat Ho' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>International Conference on Machine Learning</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://proceedings.mlr.press/v162/nguyen22e/nguyen22e.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/UT-Austin-Data-Science-Group/Mini-batch-OT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Mini-batch optimal transport (m-OT) has been widely used recently to deal with the memory issue of OT in large-scale applications. Despite their practicality, m-OT suffers from misspecified mappings, namely, mappings that are optimal on the mini-batch level but are partially wrong in the comparison with the optimal transportation plan between the original measures. Motivated by the misspecified mappings issue, we propose a novel mini-batch method by using partial optimal transport (POT) between mini-batch empirical measures, which we refer to as mini-batch partial optimal transport (m-POT). Leveraging the insight from the partial transportation, we explain the source of misspecified mappings from the m-OT and motivate why limiting the amount of transported masses among mini-batches via POT can alleviate the incorrect mappings. Finally, we carry out extensive experiments on various applications such as deep domain adaptation, partial domain adaptation, deep generative model, color transfer, and gradient flow to demonstrate the favorable performance of m-POT compared to current mini-batch methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#820000"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> <span class="award badge rounded w-100"> Spotlight </span> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DSW-480.webp 480w,/assets/img/publication_preview/DSW-800.webp 800w,/assets/img/publication_preview/DSW-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/DSW.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DSW.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="nguyen2021distributional" class="col-sm-8"> <div class="title">Distributional Sliced-Wasserstein and Applications to Generative Modeling</div> <div class="author"> <em>Khai Nguyen</em>, <a href="https://nhatptnk8912.github.io/" rel="external nofollow noopener" target="_blank">Nhat Ho</a>, Tung Pham, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Hung Bui' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>International Conference on Learning Representations</em>, 2021 </div> <div class="periodical"> </div> <span class="honor"> Spotlight Presentation [3.78%] </span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2002.07367.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/VinAIResearch/DSW" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="award hidden d-print-inline"> <p></p> <p>Spotlight</p> </div> <div class="abstract hidden"> <p>Sliced-Wasserstein distance (SW) and its variant, Max Sliced-Wasserstein distance (Max-SW), have been used widely in the recent years due to their fast computation and scalability even when the probability measures lie in a very high dimensional space. However, SW requires many unnecessary projection samples to approximate its value while Max-SW only uses the most important projection, which ignores the information of other useful directions. In order to account for these weaknesses, we propose a novel distance, named Distributional Sliced-Wasserstein distance (DSW), that finds an optimal distribution over projections that can balance between exploring distinctive projecting directions and the informativeness of projections themselves. We show that the DSW is a generalization of Max-SW, and it can be computed efficiently by searching for the optimal push-forward measure over a set of probability measures over the unit sphere satisfying certain regularizing constraints that favor distinct directions. Finally, we conduct extensive experiments with large-scale datasets to demonstrate the favorable performances of the proposed distances over the previous sliced-based distances in generative modeling applications.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6B%68%61%69%6E%62@%75%74%65%78%61%73.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/khainb" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/khai-nguyen-307895155" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://www.researchgate.net/profile/Khai-Nguyen-37/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://scholar.google.com/citations?user=im5fNaQAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/khainb_ml" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <div style="display: flex; justify-content: center; align-items: center; height: 100vh;"> <div style="width: 350px; height: 350px;"> <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=LNNe9YSbldJQ3E4CCvGOl8mNJr3g6aj37ruvunxX3Zo"></script> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Khai Nguyen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/libs/jquery/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="/assets/libs/mdb/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="/assets/libs/masonry/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="/assets/libs/imagesloaded/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script src="/assets/js/tooltips-setup.js?53023e960fbc64cccb90d32e9363de2b"></script> <script defer src="/assets/libs/medium_zoom/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="/assets/libs/mathjax/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="/assets/libs/polyfill/polyfill.min.js" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZKXM8P5V7J"></script> <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-ZKXM8P5V7J');
</script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>